"""
Citation data structures and types for the litigation document processing pipeline.

This module defines the core data structures for tracking citations throughout the pipeline.
"""

from dataclasses import dataclass, field
from typing import Optional, Dict, List
from enum import Enum


class DocumentType(Enum):
    """Supported document types with different citation formats."""
    DEPOSITION = "deposition"           # page:line format (e.g., "45:12-18")
    PATENT = "patent"                   # column:line format (e.g., "col. 3:45-55")
    EXPERT_REPORT = "expert_report"     # paragraph format (e.g., "¶ 42")
    PLEADING = "pleading"               # paragraph format (e.g., "Complaint ¶ 23")
    EXHIBIT = "exhibit"                 # page format (e.g., "Ex. 15, p. 3")
    UNKNOWN = "unknown"


@dataclass
class CitationData:
    """
    Citation metadata for a text element.

    Different document types populate different fields:
    - Depositions: page, line_start, line_end, bates
    - Patents: page, column, line_start, line_end
    - Expert Reports: page, paragraph_number
    """
    page: Optional[int] = None
    line_start: Optional[int] = None
    line_end: Optional[int] = None
    bates: Optional[str] = None
    column: Optional[int] = None
    paragraph_number: Optional[int] = None
    type: str = "unknown"

    def to_dict(self) -> dict:
        """Convert to dictionary for JSON serialization."""
        return {
            "page": self.page,
            "line_start": self.line_start,
            "line_end": self.line_end,
            "bates": self.bates,
            "column": self.column,
            "paragraph_number": self.paragraph_number,
            "type": self.type
        }


@dataclass
class ConversionResult:
    """Result of document conversion with citation extraction."""
    md_path: str
    citations_found: Dict[str, List]
    needs_reconstruction: bool
    doc_type: DocumentType = DocumentType.UNKNOWN
    errors: List[str] = field(default_factory=list)

    def citation_coverage_summary(self) -> str:
        """Generate a summary of citation coverage."""
        lines = ["Citation Coverage Summary:"]
        lines.append(f"  Document Type: {self.doc_type.value}")
        lines.append(f"  Pages Found: {len(self.citations_found.get('pages', []))}")
        lines.append(f"  Line Markers: {len(self.citations_found.get('line_markers', []))}")
        lines.append(f"  Bates Stamps: {len(self.citations_found.get('bates_stamps', []))}")
        lines.append(f"  Column Markers: {len(self.citations_found.get('column_markers', []))}")
        lines.append(f"  Paragraph Markers: {len(self.citations_found.get('paragraph_markers', []))}")
        lines.append(f"  Needs Reconstruction: {'Yes' if self.needs_reconstruction else 'No'}")

        if self.errors:
            lines.append(f"  Errors: {len(self.errors)}")
            for error in self.errors[:3]:  # Show first 3 errors
                lines.append(f"    - {error}")

        return "\n".join(lines)


@dataclass
class ProcessingResult:
    """Result of post-processing step."""
    cleaned_path: str
    citations_path: str
    citation_coverage: int
    warnings: List[str] = field(default_factory=list)

    def __str__(self) -> str:
        lines = [
            f"Processing Result:",
            f"  Cleaned File: {self.cleaned_path}",
            f"  Citations File: {self.citations_path}",
            f"  Citation Coverage: {self.citation_coverage} elements"
        ]
        if self.warnings:
            lines.append(f"  Warnings: {len(self.warnings)}")
            for warning in self.warnings[:3]:
                lines.append(f"    - {warning}")
        return "\n".join(lines)


@dataclass
class Chunk:
    """
    A semantic chunk of text with citation metadata and deterministic quotes.

    CRITICAL: key_quotes are extracted deterministically from core_text,
    NOT generated by LLM (to avoid hallucination).
    """
    chunk_id: str
    core_text: str
    pages: List[int]
    citation: Dict[str, any]
    citation_string: str
    key_quotes: List[str] = field(default_factory=list)
    tokens: int = 0
    doc_type: DocumentType = DocumentType.UNKNOWN

    def to_dict(self) -> dict:
        """Convert to dictionary for JSON serialization."""
        return {
            "chunk_id": self.chunk_id,
            "core_text": self.core_text,
            "pages": self.pages,
            "citation": self.citation,
            "citation_string": self.citation_string,
            "key_quotes": self.key_quotes,
            "tokens": self.tokens,
            "doc_type": self.doc_type.value
        }


@dataclass
class SearchResult:
    """
    A search result with score and ranking information.

    Used by hybrid retrieval to return chunks with relevance scores
    from BM25, semantic search, or both.
    """
    chunk_id: str
    chunk: Chunk
    score: float
    bm25_score: Optional[float] = None
    semantic_score: Optional[float] = None
    rank: int = 0
